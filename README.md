# ğŸ¤– Azure RAG Chatbot Template (with ChromaDB + FastAPI)

A **Retrieval-Augmented Generation (RAG)** chatbot built using **Azure OpenAI**, **FastAPI**, and **ChromaDB**, with an interactive web UI for chat and PDF upload.

This template allows you to:
- Upload PDFs dynamically ğŸ—‚ï¸  
- Store and query them using **ChromaDB** as a vector database ğŸ”  
- Chat with the AI assistant that references uploaded content ğŸ’¬  
- Easily extend the UI and backend for different assistant use cases ğŸ¯  

---

## ğŸš€ Features

âœ… **Azure OpenAI integration** for embeddings and chat completions  
âœ… **Local vector storage** using ChromaDB  
âœ… **Drag & Drop PDF upload** with automatic text extraction  
âœ… **Clean FastAPI backend** with modular structure  
âœ… **Responsive chat UI** with user/assistant bubbles  
âœ… **Easily customizable assistant behavior**

---

## ğŸ§© Project Structure
azure-rag-chatbot/
â”‚
â”œâ”€â”€ app.py # Main FastAPI application
â”‚
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ config.py # Environment and settings
â”‚ â”œâ”€â”€ pdf_loader.py # PDF parsing and ChromaDB indexing
â”‚ â”œâ”€â”€ rag_chat.py # RAG chat logic using Azure OpenAI
â”‚
â”œâ”€â”€ frontend/
â”‚ â”œâ”€â”€ templates/
â”‚ â”‚ â””â”€â”€ chat.html # Web chat UI
â”‚ â””â”€â”€ static/
â”‚ â”œâ”€â”€ css/
â”‚ â”‚ â””â”€â”€ style.css # UI styling
â”‚ â””â”€â”€ js/
â”‚ â””â”€â”€ chat.js # Client-side interactivity
â”‚
â”œâ”€â”€ .env # Environment variables
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # You are here ğŸ˜„

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/<your-username>/azure-rag-chatbot.git
cd azure-rag-chatbot
```

### 2ï¸âƒ£ Create and Activate Virtual Environment
```bash
python -m venv .venv
source .venv/bin/activate        # macOS/Linux
.venv\Scripts\activate           # Windows
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configure Environment Variables
```bash
OPEN_AI_ENDPOINT=https://<your-azure-openai-endpoint>.openai.azure.com
OPEN_AI_KEY=<your-azure-openai-key>
CHAT_MODEL=gpt-4o-mini
EMBEDDING_MODEL=text-embedding-ada-002
ASSISTANT_NAME=<your-assistant-name>
```

> âš ï¸ Ensure your Azure OpenAI resource has both a chat model (e.g. gpt-4o-mini) and embedding model (e.g. text-embedding-ada-002 deployed.

---

## â–¶ï¸ Run the Application
Start the FastAPI server:
```bash
uvicorn app:app --reload
```
Then open in your browser:

ğŸ‘‰ http://127.0.0.1:8000/chat

---

## ğŸ’¬ Using the App
1. Upload PDFs
- Drag & drop a PDF or click the upload area.
- The app automatically extracts text, chunks it, embeds it with Azure OpenAI, and stores it in ChromaDB.

2. Ask Questions
- Type questions related to the uploaded documents.
- The chatbot retrieves the most relevant chunks from ChromaDB and answers using Azure OpenAI.

3. Enjoy the Conversation
- User and assistant messages appear as chat bubbles.
- You can extend this for any assistant persona.

---

## ğŸ§  How It Works
1. Upload PDF â†’ Extract text â†’ Create embeddings (Azure OpenAI) â†’ Store in ChromaDB
2. User query â†’ Embed query â†’ Retrieve relevant chunks â†’ Provide context to Azure OpenAI
3. Azure OpenAI â†’ Generates response grounded in document context

---

## ğŸ§° Requirements
- Python 3.10+
- Azure OpenAI resource with deployed models
- (Optional) Git & Virtual Environment tools

---

## ğŸ§ª Example Queries

After uploading a travel brochure PDF:
> User: What are the destinations offered by the travel agent?

> Assistant: The travel agency offers flights to Paris, Tokyo, and Sydney with full package deals including hotels and tours.

---

## ğŸ”§ Customization

You can easily modify:
- `settings.ASSISTANT_NAME` â†’ change assistant persona
- `system_prompt` in `rag_chat.py` â†’ define tone and context
- Frontend UI â†’ add your own branding or layout

---

## ğŸš€ Deployment

### Run in Production
```bash
uvicorn app:app --host 0.0.0.0 --port 8000
```

### Containerize (Optional)
Create a simple Dockerfile:
```bash
FROM python:3.11-slim
WORKDIR /app
COPY . .
RUN pip install -r requirements.txt
CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]
```

Then:
```bash
docker build -t azure-rag-chatbot .
docker run -p 8000:8000 azure-rag-chatbot
```
---

## ğŸ§‘â€ğŸ’» Author
Farhan Rahman